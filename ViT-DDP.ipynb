{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1af4a30a",
   "metadata": {},
   "source": [
    "# Distributed Data Parallel Using 1,2,4 GPUs on Vision Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b88bbd",
   "metadata": {},
   "source": [
    "## How to run\n",
    "- Run the cell Below\n",
    "- The model will save train_ddp_vit.py\n",
    "- Run this command to train with or with Mixed Precision\n",
    "- python train_ddp_vit.py --world_size=2 --use_amp\n",
    "- world_size is number of GPUs\n",
    "- use_amp is the flag for running mixed precision\n",
    "- Run mixed precision on V100, it will not work on P100 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "124593cf-23a3-43c3-a67d-90fc2f075a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train_ddp_vit.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train_ddp_vit.py\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.data import Dataset, DataLoader, DistributedSampler\n",
    "from torchvision import transforms\n",
    "from transformers import ViTFeatureExtractor, ViTForImageClassification\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Constants\n",
    "NUM_EPOCHS = 2\n",
    "BATCH_SIZE = 16\n",
    "IMG_SIZE = 224\n",
    "SUBSET_SIZE = 8000\n",
    "DATASET_DIR = \"dataset\"\n",
    "CSV_PATH = os.path.join(DATASET_DIR, \"train.csv\")\n",
    "IMAGE_DIR = os.path.join(DATASET_DIR, \"train_data\")\n",
    "\n",
    "\n",
    "def setup(rank, world_size):\n",
    "    dist.init_process_group(\"nccl\", rank=rank, world_size=world_size)\n",
    "    torch.cuda.set_device(rank)\n",
    "\n",
    "\n",
    "def cleanup():\n",
    "    dist.destroy_process_group()\n",
    "\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, dataframe, img_dir, transform=None):\n",
    "        self.df = dataframe\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        rel_path = self.df.loc[idx, 'file_name']\n",
    "        img_path = os.path.join(self.img_dir, os.path.basename(rel_path))\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = int(self.df.loc[idx, 'label'])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "\n",
    "def get_data_loaders(rank, world_size):\n",
    "    df = pd.read_csv(CSV_PATH)\n",
    "    df.columns = df.columns.str.strip()\n",
    "    df = df.drop(columns=['Unnamed: 0'], errors='ignore')\n",
    "    df = df.sample(frac=1.0, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    train_df = df.iloc[:10000].reset_index(drop=True)\n",
    "    val_df = df.iloc[10000:12000].reset_index(drop=True)\n",
    "    test_df = df.iloc[12000:14000].reset_index(drop=True)\n",
    "\n",
    "    feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224')\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=feature_extractor.image_mean, std=feature_extractor.image_std)\n",
    "    ])\n",
    "\n",
    "    train_dataset = ImageDataset(train_df, IMAGE_DIR, transform)\n",
    "    val_dataset = ImageDataset(val_df, IMAGE_DIR, transform)\n",
    "    test_dataset = ImageDataset(test_df, IMAGE_DIR, transform)\n",
    "\n",
    "    train_sampler = DistributedSampler(train_dataset, num_replicas=world_size, rank=rank)\n",
    "    val_sampler = DistributedSampler(val_dataset, num_replicas=world_size, rank=rank)\n",
    "    test_sampler = DistributedSampler(test_dataset, num_replicas=world_size, rank=rank)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=train_sampler, num_workers=2)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, sampler=val_sampler, num_workers=2)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, sampler=test_sampler, num_workers=2)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "\n",
    "def train(model, loader, optimizer, criterion, device, scaler, use_amp):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.amp.autocast(device_type='cuda', enabled=use_amp):\n",
    "            outputs = model(images).logits\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        if use_amp:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images).logits\n",
    "            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.numpy())\n",
    "    return accuracy_score(all_labels, all_preds)\n",
    "\n",
    "\n",
    "def main(rank, world_size, use_amp):\n",
    "    setup(rank, world_size)\n",
    "\n",
    "    device = torch.device(f\"cuda:{rank}\")\n",
    "    train_loader, val_loader, test_loader = get_data_loaders(rank, world_size)\n",
    "\n",
    "    model = ViTForImageClassification.from_pretrained(\n",
    "        'google/vit-base-patch16-224',\n",
    "        num_labels=2,\n",
    "        ignore_mismatched_sizes=True\n",
    "    ).to(device)\n",
    "\n",
    "    model = DDP(model, device_ids=[rank])\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
    "\n",
    "    if rank == 0:\n",
    "        print(f\"{'With' if use_amp else 'Without'} AMP, Training with {world_size} GPU(s)\")\n",
    "\n",
    "    start = time.time()\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        train_loader.sampler.set_epoch(epoch)\n",
    "        train_loss = train(model, train_loader, optimizer, criterion, device, scaler, use_amp)\n",
    "        val_acc = evaluate(model, val_loader, device)\n",
    "        if rank == 0:\n",
    "            print(f\"Epoch {epoch+1}: Train Loss = {train_loss:.4f}, Val Acc = {val_acc:.4f}\")\n",
    "    total_time = time.time() - start\n",
    "\n",
    "    if rank == 0:\n",
    "        test_acc = evaluate(model, test_loader, device)\n",
    "        print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "        print(f\"Total training time: {total_time:.2f} seconds\")\n",
    "\n",
    "    cleanup()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--world_size\", type=int, default=1, help=\"number of GPUs\")\n",
    "    parser.add_argument(\"--use_amp\", action=\"store_true\", help=\"use Automatic Mixed Precision\")\n",
    "    parser.add_argument(\"--master_addr\", type=str, default=\"127.0.0.1\", help=\"Master address\")\n",
    "    parser.add_argument(\"--master_port\", type=str, default=\"29501\", help=\"Master port\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    os.environ[\"MASTER_ADDR\"] = args.master_addr\n",
    "    os.environ[\"MASTER_PORT\"] = args.master_port\n",
    "\n",
    "    torch.multiprocessing.spawn(\n",
    "        main,\n",
    "        args=(args.world_size, args.use_amp),\n",
    "        nprocs=args.world_size,\n",
    "        join=True\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a565802a-6f1b-412e-a2fc-e73a8bfbe1b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
